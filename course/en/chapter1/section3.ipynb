{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsbu7KOUtpTJ"
      },
      "source": [
        "# Transformers, what can they do?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLrgQoe_tpTL"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5Rg8LEDtpTL",
        "outputId": "f5c7f098-0f07-4aca-f06a-89c86cd3e2d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.12/dist-packages (4.57.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.35.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]) (0.6.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]) (0.2.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]) (5.29.5)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqFJbz9KtpTM"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSdgTSa7tpTN"
      },
      "outputs": [],
      "source": [
        "classifier(\n",
        "    [\"I've been waiting for a HuggingFace course my whole life.\", \"I don't understand this course but I like this so much!\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPSaYuC8tpTN"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    \"This is a course about the Transformers library\",\n",
        "    candidate_labels=[\"education\", \"politics\", \"business\", \"learning-curve\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsPuVJ99tpTN"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\")\n",
        "generator(\"In this course, we will teach you how to\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxUc1uRjtpTN"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "generator(\n",
        "    \"In this course, we will teach you how to\",\n",
        "    max_length=30,\n",
        "    num_return_sequences=2,\n",
        ")\n",
        "print(\"Model config:\", generator.model.config)\n",
        "print(\"Model URL:\", f\"https://huggingface.co/{generator.model.name_or_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"HuggingFaceTB/SmolLM2-360M\")\n",
        "generator(\n",
        "    \"In this course, we will teach you how to\",\n",
        "    max_length=30,\n",
        "    num_return_sequences=2,\n",
        ")\n",
        "print(\"Model config:\", generator.model.config)\n",
        "print(\"Model URL:\", f\"https://huggingface.co/{generator.model.name_or_path}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "VvxElDay0GqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"bigscience/bloom\")\n",
        "generator(\n",
        "    \"In this course, we will teach you how to\",\n",
        "    max_length=30,\n",
        "    num_return_sequences=2,\n",
        ")\n",
        "print(\"Model config:\", generator.model.config)\n",
        "print(\"Model URL:\", f\"https://huggingface.co/{generator.model.name_or_path}\")"
      ],
      "metadata": {
        "id": "ZyCR0nJf16od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlHqqad-tpTO"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\")\n",
        "unmasker(\"This course will teach you all about <mask> models.\", top_k=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\",model=\"google-bert/bert-base-multilingual-cased\")\n",
        "unmasker(\"This course will teach you all about <mask> models.\", top_k=2)"
      ],
      "metadata": {
        "id": "WrbdFj0ucvjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkKt3smStpTO"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "ner(\"My name is Prasanth and I work at Hugging Face in China. and my favourite fruit is apple\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_LJ6j2ztpTO"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "question_answerer = pipeline(\"question-answering\")\n",
        "question_answerer(\n",
        "    question=\"what is my working place ?\",\n",
        "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn and I dont like apple \",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0QVuvhdtpTO"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\",max_length=10)\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "    America has changed dramatically during recent years. Not only has the number of\n",
        "    graduates in traditional engineering disciplines such as mechanical, civil,\n",
        "    electrical, chemical, and aeronautical engineering declined, but in most of\n",
        "    the premier American universities engineering curricula now concentrate on\n",
        "    and encourage largely the study of engineering science. As a result, there\n",
        "    are declining offerings in engineering subjects dealing with infrastructure,\n",
        "    the environment, and related issues, and greater concentration on high\n",
        "    technology subjects, largely supporting increasingly complex scientific\n",
        "    developments. While the latter is important, it should not be at the expense\n",
        "    of more traditional engineering.\n",
        "\n",
        "    Rapidly developing economies such as China and India, as well as other\n",
        "    industrial countries in Europe and Asia, continue to encourage and advance\n",
        "    the teaching of engineering. Both China and India, respectively, graduate\n",
        "    six and eight times as many traditional engineers as does the United States.\n",
        "    Other industrial countries at minimum maintain their output, while America\n",
        "    suffers an increasingly serious decline in the number of engineering graduates\n",
        "    and a lack of well-educated engineers.\n",
        "\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlHX2l-ttpTP"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
        "translator(\"Ce cours est produit par Hugging Face.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation\", model=\"microsoft/bitnet-b1.58-2B-4T\")\n",
        "translator(\"Ce cours est produit par Hugging Face.\")"
      ],
      "metadata": {
        "id": "0rQ9wwu2jSYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using the demo on text classification by using distilBERT model\n",
        "!pip install transformers datasets evaluate accelerate"
      ],
      "metadata": {
        "id": "fta_IVShnD21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login"
      ],
      "metadata": {
        "id": "76YNWlr5neAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "RdIgKnEUnhHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "imdb = load_dataset(\"imdb\")"
      ],
      "metadata": {
        "id": "aDbRISgzn0pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb[\"train\"][1]"
      ],
      "metadata": {
        "id": "eR-dVI1_n9Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "pEJ-hm6wos6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
      ],
      "metadata": {
        "id": "T_1MhaBOo07_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)"
      ],
      "metadata": {
        "id": "_ucl-u5cpCnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_imdb = imdb.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "Oj5uI6eQpE5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_imdb[\"train\"][0]"
      ],
      "metadata": {
        "id": "ErKymXa7piKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "BYcOLTffpzgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate"
      ],
      "metadata": {
        "id": "j4qodGqcp7Nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = evaluate.load(\"accuracy\")\n",
        "accuracy"
      ],
      "metadata": {
        "id": "KvPhKDMup7tC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "YkvH1bnCqNpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "yyAfxouxqT_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
      ],
      "metadata": {
        "id": "R6Ux6WU6qeif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
        ")"
      ],
      "metadata": {
        "id": "v3nEcIBfqock"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"my_awesome_model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=100,\n",
        "    per_device_eval_batch_size=100,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "id": "7Gvu4EBJsNqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_imdb[\"train\"].select(range(2000)),\n",
        "    eval_dataset=tokenized_imdb[\"test\"].select(range(2000)),\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "h5z7iBjosaJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "W-5W_Zt0sd5q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Transformers, what can they do?",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}